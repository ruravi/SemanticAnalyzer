
user:ruravi
user:peterhu

README file for Programming Assignment 3 (Java edition)
======================================================

Your directory should now contain the following files:

 ASTConstants.java    -> [class dir]/src/PA3J/ASTConstants.java
 ASTLexer.java	      -> [class dir]/src/PA3J/ASTLexer.java
 ASTParser.java	      -> [class dir]/src/PA3J/ASTParser.java
 AbstractSymbol.java  -> [class dir]/src/PA3J/AbstractSymbol.java
 AbstractTable.java   -> [class dir]/src/PA3J/AbstractTable.java
 BoolConst.java       -> [course dir]/src/PA3J/BoolConst.java
 ClassTable.java
 Flags.java	      -> [class dir]/src/PA3J/Flags.java
 IdSymbol.java	      -> [class dir]/src/PA3J/IdSymbol.java
 IdTable.java	      -> [class dir]/src/PA3J/IdTable.java
 IntSymbol.java	      -> [class dir]/src/PA3J/IntSymbol.java
 IntTable.java	      -> [class dir]/src/PA3J/IntTable.java
 ListNode.java	      -> [class dir]/src/PA3J/ListNode.java
 Makefile	      -> [class dir]/etc/../assignments/PA3J/Makefile
 README
 Semant.java	      -> [class dir]/src/PA3J/Semant.java
 StringSymbol.java    -> [class dir]/src/PA3J/StringSymbol.java
 StringTable.java     -> [class dir]/src/PA3J/StringTable.java
 SymbolTable.java     -> [class dir]/src/PA3J/SymbolTable.java
 SymtabExample.java   -> [class dir]/src/PA3J/SymtabExample.java
 TokenConstants.java  -> [class dir]/src/PA3J/TokenConstants.java
 TreeConstants.java
 TreeNode.java	      -> [class dir]/src/PA3J/TreeNode.java
 Utilities.java	      -> [class dir]/src/PA3J/Utilities.java
 bad.cl
 cool-tree.aps	      -> [class dir]/src/PA3J/cool-tree.aps
 cool-tree.java
 good.cl

	The Makefile contains targets for compiling and running your
	program. DO NOT MODIFY.

	The README contains this info. Part of the assignment is to fill
	the README with the write-up for your project. You should
	explain design decisions, explain why your code is correct, and
	why your test cases are adequate. It is part of the assignment
	to clearly and concisely explain things in text as well as to
	comment your code.  Just edit this file.

	good.cl and bad.cl test a few features of the semantic checker.
	You should add tests to ensure that good.cl exercises as many
	legal semantic combinations as possible and that bad.cl
	exercises as many kinds of semantic errors as possible.

	cool-tree.aps contains the definitions for the tree language
	which you use to construct the abstract syntax tree (AST). This
	file is provided for your reference.  DO NOT MODIFY.

        TreeNode.java and ListNode.java contain definitions used by the
        tree package. DO NOT MODIFY.  

        cool-tree.java specifies and gives an implementation of Cool ASTs
        (see the README for PA3 and the "Cool Tour").  In this
        assignment, you will need to add functions to the AST classes to
        store, fetch, and compute information about the AST.

   	You should NOT remove any definitions that are already present
   	in cool-tree.java.  These function and data members are required
   	for the system to function properly.

        You should add any fields and methods to the classes you need to
        perform semantic analysis.  You will need to add, for example,
        methods which traverse the expressions of the tree and implement
        the type-checking rules.  The entry point to the semantic
        analyzer is program.semant().

	ClassTable.java implements a placeholder class for a few useful
	methods.  Feel free to extend it to implement some real data
	strucutre.

	TreeConstants.java defined some useful symbol constants.  You
	may add some of your own, if you wish.

	ASTLexer.java, ASTParser.java, and ASTConstants.java implement a
	lexer and a parser for reading text representation of ASTs from
	console in the format produced by the parser phase. DO NOT
	MODIFY.

        Semant.java contains a driver to test the analyzer.  The main
        method reads an AST in text form from standard input, parses it,
        and then produces a type-annotated AST on standard output.  The
        script mycoolc can pass any of the standard flags to the
        semantic analyzer as well; for this assignment, -s (semantic
        analysis debug) may be useful as it sets a static variable
        Flags.semant_debug to "true".  If you want your semantic checker
        to print debug information when the option is set, write your
        debug code in the following format:

	      if (Flags.semant_debug)
	      {
		...
	      }

	semant_debug is provided as a convenience. You don't need to use
	the debugging flags if you don't want to. DON'T MODIFY
	Semant.java

	SymbolTable.java contains a symbol table implementation. Read
	the comments in the file and look at the example in
	SymtabExample.java.  You are not required to use this code, but
	you may find it useful. DO NOT MODIFY.

Instructions
------------

	To compile the example use of the symbol table, type

	% gmake symtab-example

	This creates a shell script to run the symbol table example.

	To compile your semantic analyzer program type:

	% gmake semant

	To test your semantic checker, type:

	% mysemant foo.cl

	mysemant is a version of mycoolc that omits code generation.
	mysemant parses all the cool files given on the command line and
	builds a single abstract syntax tree containing all class
	definitions appearing in the input files. Your semantic checker
	is then called on this abstract syntax tree.  If there are no
	errors, the program produces a type-annotated abstract syntax
	tree as output.

	To run your checker on the files good.cl and bad.cl type:

	% gmake dotest

	If you think your semantic checker is correct and behaves like
	the one we wrote, you can try to run mycoolc using your checker,
	your parser and also your lexical analyzer if you choose (see
	below for instructions).  Remember if your lexer, parser or
	checker behaves in an unexpected manner, you may get errors
	anywhere.

	To turnin your work type:

	% gmake submit-clean

	And run the "submit" program following the instructions on the
	course web page.
	
	Running "submit" will collect the files cool-tree.java,
	ClassTable.java, TreeConstants.java, good.cl, bad.cl,
	good.output, bad.output, and README. Don't forget to edit the
	README file to include your write-up, and to write your own test
	cases in good.cl and bad.cl.

 	You may turn in the assignment as many times as you like.
 	However, only the last version will be retained for grading.

	If you change architectures you must issue

	% gmake clean

	when you switch from one type of machine to the other.
	If at some point you get weird errors from the linker,	
	you probably forgot this step.

	GOOD LUCK!

---8<------8<------8<------8<---cut here---8<------8<------8<------8<---

Write-up for PA3
----------------

DESIGN DECISIONS AND CORRECTNESS OF ALGORITHMS

Inheritance Tree
	To keep track of class dependencies and to make sure there are no
	cyclic dependencies, we used a directed graph. Our representation of this
	 graph was a HashMap of nodes to a list of all the nodes' children, where a 
	 node in this case is the toString value of a unique class type. We chose 
	 this data structure because it is a very simple and intuitive way of modeling 
	 this directed graph. Starting from the object class, we now have a top down 
	 directed graph. We also made a hashmap of string names of class types to the
	 actual class_c types to make looking up of actual class_c data types efficient. 

	Building the Tree
	To initialize this hashmap, we add IO, Int, Bool, and Str to the list of children
	 of Object (as defined by the starter code), the root node in our inheritance 
	 tree. From the given list of classes, we iterate through all classes. If the
	 class name is already present in our hashmap nameToClass, then there is a 
	 redefinition error. If the new class is not present, then we add it to our
	 nameToClass hashmap. We then check if the parent of the current node exists 
	 in our hashmap, and if so, add the given node to its parent's list of children.   

	Cycle Checking
	We checked for cycles by using depth first traversal on our inheritance tree to 
	mark all visited nodes. We begin at the root, and recurse on the children of each 
	node, marking a node as we visit it in this top down approach. If we visit a node
	that has already been marked as true/visited, then we know a cycle exists. 

1st Pass: Naming and Scoping

	We implemented naming and scoping in the programc class. We first declared
	two symbol tables to keep track of the scope, one for objects symbols and 
	one for method symbols. The first time we traverseAST we want to set the 
	scope of all classes, methods, and attributes. We then
	assign types to all possible expressions inside the methods
	and attributes. For each class, we begin a new scope and traverse down the class AST. 
	While inside the class, we add all methods and attributes to their respective object 
	and method symbol tables. When the method or attribute gives way
	to an expression, we traverse the Expression to assign types and 
	do scoping in the expression. We separate out each type of expression in cascading 
	if statements, where we set the static types of each expression to that outlined 
	on the assignment handout. This is true for all expressions except for dispatch 
	and static dispatch, in which we don't know the type of the
	expression (temporarily null type) until we specifically assign a type during type checking. 
	This approach is correct because if the type can be computed, then we should 
	immediately annotate the type in the AST. This will make type checking easier the next
	time we make a pass through the AST. Because entering and exiting scopes are analgous
	to pushing/popping a stack, we cannot save data in the scope past the first entry. This 
	is why we decided to first make an initial pass through the AST to add all the data accessible
	throught the first scope (methods and attributes inside every class). 

	Traversing Expressions
	Most of the assignments of types were straightforward, except for
	a few cases. For let expressions and case branches we entered
	new scopes for each branch, and added the types to the object symbol tables 
	in the scope. For condition statements and case statements, the static type
	also needed to be determined by finding the type of the lowest common ancestor. 
	The annotations for the rest of the expressions had types that did not need 
	further computation. This design is correct because everytime we enter a new
	method or case branch, we enter a new scope, and thus need to add the objects
	to the symboltables to keep track. 

	Lowest Common Ancestor (Explanation and Correctness)
	We constructed a hashmap of string names of class types to its associated 
	depth in the tree. The depth hashmap makes finding the least common ancestor 
	of a given list of nodes a lot easier. Our algorithm for checking the LCA 
	consisted of finding the depths of all nodes in our inheritance graph, where
	the root node is at depth zero. Given a list of input types, we want to return
	the LCA. For each type in the arraylist of input types, we determine the depth, 
	and then find the lowest depth among them (depth closest to the root). We then 
	call get parent on all nodes until they are all at the lowest common depth. This 
	is correct because the LCA is at least at the lowest common depth. After all 
	nodes are at the lowest common depth, we call getparent on the nodes and compare. 
	If all are equal, then we return the type of any one of those nodes.                                                                                                                                                                                                                                    
2nd pass: Type Checking and Filling in Inherited Methods/Attributes
	
	We traverse the AST again a second time to fill in methods and attributes inherited
	from the parent class, and we type check these methods and 
	attributes along the way. For each method and attribute, when
	typechecking, we typecheck the expressions inside them as well. 
	In this traversal of the AST, we are mainly checking for dispatch types. 
	Because the types of the dispatches could not be determined in the first traversal, 
	we assign types to dispatch and static dispatch in this second pass.
	For each expression, we recursively type check any branching expression.
	For those expressions whose types have already been assigned in the first traversal
	of the AST, we do not set the types again. For expressions that 
	might include dispatch, however, we set the types here in this second traversal. 
	This approach is correct, because for types that have already been annotated, we do 
	not need to annotate them again. Thus, only for expressions that could have dispatch
	do we set_type of the given expression. 

TEST CASES

We placed our tests in a folder named "tests"
We tested correctness of output by using a script that checks the difference 
between the output of our semantic analyzer and the reference semantic analyzer.

To make our code more robust, the following test cases were constructed and used. 

Good tests (good.cl)

	Assigning self_types
	general Inheritance
	general formals with the 3 types (Int, bool, string)
	Using methods before declarations
	dispatch to a method that hasn't been declared yet
	general assignment expressions
	Expression constants (int/bool/string)
	Reassigning constants to the same Object
	If statement with dispatch expression
	let statement with init
	let statement without init
	valid case statements
	valid loop, isvoid, not, arithmetic, compare, neg, and equals statements


Error Tests (bad.cl)

	Illegal attribute assignments
	Illegal use of self_type in formal parameters
	parameter mismatch in formals
	Illegal number of arguments in methods
	undefined methods
	Invalid dispatch and static dispatch formats
	Illegal Overriding
	Invalid Overriding by changing the signature
	Invalid format for arithmetic, not, isvoid, compare statements
	invalid return types 
	Invalid equalities

Inheritance Tests
	(inheritancegraph2.cl)
	Test for cycles in inheritance graph 

	(inheritancegraph1.cl)
	Test for valid inheritances 
	Test for classes that inherit from int, string, bool, and IO

We intentionally tried to break our semantic analyzer with the test cases 
to ensure that our code was robust, and made sure that for every test case
our analyzer had the same output as that of the reference analyzer. 